# Dataset Tools Module

This module contains comprehensive tools for diagnosing and fixing dataset issues, particularly for YOLO training with COCO annotations.

## ğŸ¯ Overview

The dataset tools help you:
- **Diagnose** dataset configuration issues
- **Fix** class configuration problems
- **Validate** dataset structure and format
- **Convert** COCO annotations to proper YOLO format

## ğŸ“ Structure

```
tests/dataset_tools/
â”œâ”€â”€ __init__.py              # Module initialization
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ diagnose_dataset.py      # Dataset diagnostic tool
â”œâ”€â”€ fix_dataset_classes.py   # Manual fix for class issues
â”œâ”€â”€ fix_dataset_ultralytics.py # Fix using Ultralytics tools
â”œâ”€â”€ dataset_validator.py    # Comprehensive validation
â”œâ”€â”€ extract_and_check_dataset.py # Extract and verify dataset structure
â”œâ”€â”€ final_verification.py   # Final dataset verification for YOLO training
â”œâ”€â”€ fix_yolo_coordinates.py # Fix coordinate normalization issues
â”œâ”€â”€ check_segmentation_format.py # Check dataset format for segmentation
â”œâ”€â”€ fix_segmentation_labels.py # Convert labels to segmentation format
â”œâ”€â”€ test_dataset_fix_integration.py # Integration test for DatasetManager
â””â”€â”€ run_dataset_fix_test.py # Test runner script
```

## ğŸ› ï¸ Tools

### 1. Dataset Diagnostic (`diagnose_dataset.py`)

**Purpose**: Identify issues with your dataset configuration

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.diagnose_dataset

# Python import
from tests.dataset_tools import diagnose_dataset
results = diagnose_dataset()
```

**What it checks**:
- âœ… `data.yaml` configuration
- âœ… COCO annotation files
- âœ… Roboflow project settings
- âœ… Class configuration issues

### 2. Dataset Validator (`dataset_validator.py`)

**Purpose**: Comprehensive validation of dataset structure and format

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.dataset_validator

# Python import
from tests.dataset_tools import validate_dataset
results = validate_dataset()
```

**What it validates**:
- ğŸ“ Directory structure
- ğŸ“„ `data.yaml` format and content
- ğŸ“‹ COCO annotation format
- ğŸ–¼ï¸ Image file integrity
- ğŸ·ï¸ Class configuration

### 3. Manual Fix (`fix_dataset_classes.py`)

**Purpose**: Fix class issues by modifying existing COCO files

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.fix_dataset_classes

# Python import
from tests.dataset_tools import fix_dataset_classes
results = fix_dataset_classes()
```

**What it does**:
- ğŸ”§ Normalizes COCO annotations to use only 'sampah' category
- ğŸ“„ Updates `data.yaml` to use only 'sampah' class
- âœ… Verifies the fix was successful

### 4. Ultralytics Fix (`fix_dataset_ultralytics.py`) â­ **RECOMMENDED**

**Purpose**: Convert COCO to proper YOLO format using official Ultralytics tools

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.fix_dataset_ultralytics

# Python import
from tests.dataset_tools import fix_dataset_ultralytics
results = fix_dataset_ultralytics()
```

**What it does**:
- ğŸ”„ Converts COCO annotations to YOLO format
- ğŸ“ Creates proper directory structure (`images/` and `labels/`)
- ğŸ“„ Creates correct `data.yaml` configuration
- ğŸ’¾ Creates backup of original dataset
- âœ… Verifies the conversion

### 5. Dataset Extraction and Check (`extract_and_check_dataset.py`)

**Purpose**: Extract dataset zip file and verify its structure

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.extract_and_check_dataset

# Python import
from tests.dataset_tools import extract_and_check_dataset
results = extract_and_check_dataset()
```

**What it does**:
- ğŸ“¦ Extracts `datasets.zip` file
- ğŸ” Checks extracted dataset structure
- ğŸ“Š Reports image and label counts
- âœ… Verifies COCO JSON files exist
- ğŸ“„ Validates `data.yaml` configuration

### 6. Final Verification (`final_verification.py`)

**Purpose**: Comprehensive final verification before YOLO training

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.final_verification

# Python import
from tests.dataset_tools import final_verification
results = final_verification()
```

**What it does**:
- ğŸ” Checks complete dataset structure
- ğŸ“¸ Validates image-label matching
- ğŸ“„ Verifies `data.yaml` paths and classes
- ğŸ¯ Ensures coordinates are within bounds
- âœ… Confirms readiness for YOLO training

### 7. Coordinate Fix (`fix_yolo_coordinates.py`)

**Purpose**: Fix "non-normalized or out of bounds coordinates" errors

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.fix_yolo_coordinates

# Python import
from tests.dataset_tools import fix_yolo_coordinates
results = fix_yolo_coordinates()
```

**What it does**:
- ğŸ”§ Re-generates YOLO labels with precise coordinate normalization
- ğŸ“ Uses actual image dimensions from COCO JSON
- âœ… Ensures all coordinates are within 0-1 range
- ğŸ¯ Fixes "out of bounds coordinates" training errors
- ğŸ“Š Reports coordinate statistics

### 8. Segmentation Format Check (`check_segmentation_format.py`)

**Purpose**: Check if dataset is properly formatted for YOLO segmentation training

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.check_segmentation_format

# Python import
from tests.dataset_tools import check_segmentation_format
results = check_segmentation_format()
```

**What it does**:
- ğŸ” Analyzes dataset structure for segmentation compatibility
- ğŸ“‹ Checks COCO annotations for segmentation data
- ğŸ“„ Validates data.yaml configuration
- ğŸ·ï¸ Verifies YOLO label format
- âœ… Confirms readiness for segmentation training

### 9. Segmentation Labels Fix (`fix_segmentation_labels.py`)

**Purpose**: Convert YOLO detection labels to segmentation labels

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.fix_segmentation_labels

# Python import
from tests.dataset_tools import fix_segmentation_labels
results = fix_segmentation_labels()
```

**What it does**:
- ğŸ”„ Converts detection labels to segmentation format
- ğŸ“ Uses polygon coordinates from COCO annotations
- ğŸ¯ Normalizes coordinates to 0-1 range
- âœ… Creates proper YOLO segmentation labels
- ğŸ“Š Reports conversion statistics

### 10. Segmentation Integration Test (`test_segmentation_integration.py`)

**Purpose**: Test the integration of segmentation fixing into DatasetManager class

**Usage**:
```bash
# Command line
python -m tests.dataset_tools.test_segmentation_integration

# Python import
from tests.dataset_tools import test_segmentation_integration
success = test_segmentation_integration()
```

**What it tests**:
- âœ… Polygon coordinate normalization
- âœ… Invalid polygon handling
- âœ… Out of bounds coordinate clamping
- âœ… Integration with DatasetManager class
- âœ… Method availability and functionality

## ğŸš€ Quick Start

### Step 1: Diagnose Your Dataset
```bash
python -m tests.dataset_tools.diagnose_dataset
```

### Step 2: Fix Issues (Choose One)

**Option A: Use Ultralytics Tools (Recommended)**
```bash
python -m tests.dataset_tools.fix_dataset_ultralytics
```

**Option B: Manual Fix**
```bash
python -m tests.dataset_tools.fix_dataset_classes
```

### Step 3: Validate the Fix
```bash
python -m tests.dataset_tools.dataset_validator
```

## ğŸ“‹ Common Issues and Solutions

### Issue: "Multiple classes found in training results"
**Solution**: Use `fix_dataset_ultralytics.py` to convert to proper YOLO format

### Issue: "No label found in segment set"
**Solution**: Use `fix_dataset_ultralytics.py` to convert COCO to YOLO format

### Issue: "data.yaml has wrong classes"
**Solution**: Use `fix_dataset_classes.py` or `fix_dataset_ultralytics.py`

### Issue: "COCO file not found"
**Solution**: Check dataset path and run `diagnose_dataset.py` to identify issues

## ğŸ”§ Advanced Usage

### Programmatic Usage
```python
from tests.dataset_tools import (
    diagnose_dataset,
    validate_dataset,
    fix_dataset_ultralytics,
    fix_dataset_classes
)

# Diagnose issues
diagnosis = diagnose_dataset(verbose=False)
if diagnosis.get('has_issues'):
    print(f"Found {len(diagnosis['all_issues'])} issues")

# Fix using Ultralytics tools
results = fix_dataset_ultralytics(verbose=False)
if results.get('success'):
    print("Dataset fixed successfully!")

# Validate the fix
validation = validate_dataset(verbose=False)
if validation['valid']:
    print("Dataset is ready for training!")
```

### Custom Dataset Path
```python
# Specify custom dataset path
results = diagnose_dataset(dataset_path="path/to/your/dataset")
fix_results = fix_dataset_ultralytics(dataset_path="path/to/your/dataset")
```

## ğŸ“Š Expected Results

### After Successful Fix
- âœ… Only "sampah" class in confusion matrix
- âœ… Proper YOLO directory structure
- âœ… Clean training results
- âœ… Backup preserved

### Directory Structure (After Ultralytics Fix)
```
datasets/your_dataset/
â”œâ”€â”€ data.yaml
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

## ğŸ¯ Which Tool to Use?

| Scenario | Recommended Tool |
|----------|------------------|
| **First time setup** | `extract_and_check_dataset.py` â†’ `fix_dataset_ultralytics.py` |
| **Quick fix** | `fix_dataset_ultralytics.py` |
| **Manual fix** | `fix_dataset_classes.py` |
| **Coordinate issues** | `fix_yolo_coordinates.py` |
| **Segmentation format** | `check_segmentation_format.py` |
| **Segmentation labels** | `fix_segmentation_labels.py` |
| **Final verification** | `final_verification.py` |
| **Validation** | `dataset_validator.py` |
| **Troubleshooting** | `diagnose_dataset.py` |

## ğŸ§ª Integration Tests

### 5. Dataset Fix Integration Test (`test_dataset_fix_integration.py`)

**Purpose**: Test the integrated dataset fixing functionality in DatasetManager

**Usage**:
```bash
# Direct execution
python tests/dataset_tools/test_dataset_fix_integration.py

# Using runner script
python tests/dataset_tools/run_dataset_fix_test.py
```

**What it tests**:
- âœ… Dataset validation functionality
- âœ… Dataset fixing with Ultralytics tools
- âœ… Dataset preparation workflows
- âœ… Individual method testing
- âœ… Error handling and recovery

### 6. Test Runner (`run_dataset_fix_test.py`)

**Purpose**: Convenient runner script for integration tests

**Usage**:
```bash
# Run integration test with proper setup
python tests/dataset_tools/run_dataset_fix_test.py
```

**Features**:
- ğŸ”§ Automatic path setup
- ğŸ“ Project root detection
- âš¡ Error handling
- ğŸ“Š Test result reporting

## ğŸ” Troubleshooting

### Error: "Ultralytics not installed"
```bash
pip install ultralytics
```

### Error: "Dataset path not found"
- Run from project root directory
- Check if dataset exists in expected location
- Use `diagnose_dataset.py` to find issues

### Error: "Backup failed"
- Check disk space
- Ensure write permissions
- Try manual backup first

## ğŸ“š References

- [Ultralytics JSON2YOLO](https://github.com/ultralytics/JSON2YOLO)
- [Ultralytics Segmentation Documentation](https://docs.ultralytics.com/datasets/segment/)
- [COCO Format Specification](https://cocodataset.org/#format-data)

## ğŸ¤ Contributing

To add new tools or improve existing ones:

1. Add your script to `tests/dataset_tools/`
2. Update `__init__.py` with imports
3. Add documentation to this README
4. Test with your dataset

## ğŸ“ License

This module is part of the main project and follows the same license terms. 